{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ---\n",
                "# title: Mandelbrot in Mojo with Python plots\n",
                "# description: Learn how to write high-performance Mojo code and import Python packages.\n",
                "# website:\n",
                "#   open-graph:\n",
                "#     image: /static/images/mojo-social-card.png\n",
                "#   twitter-card:\n",
                "#     image: /static/images/mojo-social-card.png\n",
                "# ---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[//]: # REMOVE_FOR_WEBSITE\n",
                "*Copyright 2023 Modular, Inc: Licensed under the Apache License v2.0 with LLVM Exceptions.*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[//]: # REMOVE_FOR_WEBSITE\n",
                "# Mandelbrot in Mojo with Python plots\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Not only is Mojo great for writing high-performance code, but it also allows us to leverage the huge Python ecosystem of libraries and tools. With seamless Python interoperability, Mojo can use Python for what it's good at, especially GUIs, without sacrificing performance in critical code. Let's take the classic Mandelbrot set algorithm and implement it in Mojo.\n",
                "\n",
                "This tutorial shows two aspects of Mojo. First, it shows that Mojo can be used to develop fast programs for irregular applications. It also shows how we can leverage Python for visualizing the results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "#|code-fold: true\n",
                "import benchmark\n",
                "from complex import ComplexSIMD, ComplexFloat64\n",
                "from math import iota\n",
                "from python import Python\n",
                "from sys.info import num_physical_cores\n",
                "from algorithm import parallelize, vectorize\n",
                "from tensor import Tensor\n",
                "from utils.index import Index\n",
                "\n",
                "alias float_type = DType.float64\n",
                "alias simd_width = 2 * simdwidthof[float_type]()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "First set some parameters, you can try changing these to see different results:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "alias width = 960\n",
                "alias height = 960\n",
                "alias MAX_ITERS = 200\n",
                "\n",
                "alias min_x = -2.0\n",
                "alias max_x = 0.6\n",
                "alias min_y = -1.5\n",
                "alias max_y = 1.5"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The core [Mandelbrot](https://en.wikipedia.org/wiki/Mandelbrot_set) algorithm involves computing an iterative complex function for each pixel until it \"escapes\" the complex circle of radius 2, counting the number of iterations to escape:\n",
                "\n",
                "$$z_{i+1} = z_i^2 + c$$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute the number of steps to escape.\n",
                "def mandelbrot_kernel(c: ComplexFloat64) -> Int:\n",
                "    z = c\n",
                "    for i in range(MAX_ITERS):\n",
                "        z = z * z + c\n",
                "        if z.squared_norm() > 4:\n",
                "            return i\n",
                "    return MAX_ITERS\n",
                "\n",
                "\n",
                "def compute_mandelbrot() -> Tensor[float_type]:\n",
                "    # create a matrix. Each element of the matrix corresponds to a pixel\n",
                "    t = Tensor[float_type](height, width)\n",
                "\n",
                "    dx = (max_x - min_x) / width\n",
                "    dy = (max_y - min_y) / height\n",
                "\n",
                "    y = min_y\n",
                "    for row in range(height):\n",
                "        x = min_x\n",
                "        for col in range(width):\n",
                "            t[Index(row, col)] = mandelbrot_kernel(ComplexFloat64(x, y))\n",
                "            x += dx\n",
                "        y += dy\n",
                "    return t"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Plotting the number of iterations to escape with some color gives us the canonical Mandelbrot set plot. To render it we can directly leverage Python's `matplotlib` right from Mojo!\n",
                "\n",
                "First install the required libraries:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "numpy not found, installing...\n",
                        "\u001b[33mDEPRECATION: Loading egg at /opt/homebrew/Cellar/gpgme/1.23.2/lib/python3.12/site-packages/gpg-1.23.2-py3.12-macosx-13-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
                        "\u001b[0mCollecting numpy\n",
                        "  Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m472.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
                        "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
                        "\u001b[?25hInstalling collected packages: numpy\n",
                        "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
                        "openvino 2023.3.0 requires openvino-telemetry>=2023.2.1, which is not installed.\u001b[0m\u001b[31m\n",
                        "\u001b[0mSuccessfully installed numpy-1.26.4\n",
                        "matplotlib not found, installing...\n",
                        "\u001b[33mDEPRECATION: Loading egg at /opt/homebrew/Cellar/gpgme/1.23.2/lib/python3.12/site-packages/gpg-1.23.2-py3.12-macosx-13-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
                        "\u001b[0mCollecting matplotlib\n",
                        "  Downloading matplotlib-3.8.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
                        "Collecting contourpy>=1.0.1 (from matplotlib)\n",
                        "  Downloading contourpy-1.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
                        "Collecting cycler>=0.10 (from matplotlib)\n",
                        "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
                        "Collecting fonttools>=4.22.0 (from matplotlib)\n",
                        "  Downloading fonttools-4.49.0-cp312-cp312-macosx_10_9_universal2.whl.metadata (159 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.1/159.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
                        "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
                        "  Downloading kiwisolver-1.4.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
                        "Requirement already satisfied: numpy<2,>=1.21 in /opt/homebrew/opt/python@3.12/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
                        "Collecting packaging>=20.0 (from matplotlib)\n",
                        "  Using cached packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n",
                        "Collecting pillow>=8 (from matplotlib)\n",
                        "  Downloading pillow-10.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
                        "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
                        "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
                        "Collecting python-dateutil>=2.7 (from matplotlib)\n",
                        "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
                        "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib)\n",
                        "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
                        "Downloading matplotlib-3.8.3-cp312-cp312-macosx_11_0_arm64.whl (7.5 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
                        "\u001b[?25hDownloading contourpy-1.2.0-cp312-cp312-macosx_11_0_arm64.whl (242 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.6/242.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
                        "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
                        "Downloading fonttools-4.49.0-cp312-cp312-macosx_10_9_universal2.whl (2.8 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
                        "\u001b[?25hDownloading kiwisolver-1.4.5-cp312-cp312-macosx_11_0_arm64.whl (64 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hUsing cached packaging-24.0-py3-none-any.whl (53 kB)\n",
                        "Downloading pillow-10.2.0-cp312-cp312-macosx_11_0_arm64.whl (3.3 MB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
                        "\u001b[?25hDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
                        "\u001b[?25hUsing cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
                        "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
                        "Installing collected packages: six, pyparsing, pillow, packaging, kiwisolver, fonttools, cycler, contourpy, python-dateutil, matplotlib\n",
                        "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.49.0 kiwisolver-1.4.5 matplotlib-3.8.3 packaging-24.0 pillow-10.2.0 pyparsing-3.1.2 python-dateutil-2.9.0.post0 six-1.16.0\n"
                    ]
                }
            ],
            "source": [
                "%%python\n",
                "from importlib.util import find_spec\n",
                "import shutil\n",
                "import subprocess\n",
                "\n",
                "fix = \"\"\"\n",
                "-------------------------------------------------------------------------\n",
                "fix following the steps here:\n",
                "    https://github.com/modularml/mojo/issues/1085#issuecomment-1771403719\n",
                "-------------------------------------------------------------------------\n",
                "\"\"\"\n",
                "\n",
                "def install_if_missing(name: str):\n",
                "    if find_spec(name):\n",
                "        return\n",
                "\n",
                "    print(f\"{name} not found, installing...\")\n",
                "    try:\n",
                "        if shutil.which('python3'): python = \"python3\"\n",
                "        elif shutil.which('python'): python = \"python\"\n",
                "        else: raise (\"python not on path\" + fix)\n",
                "        subprocess.check_call([python, \"-m\", \"pip\", \"install\", name])\n",
                "    except:\n",
                "        raise ImportError(f\"{name} not found\" + fix)\n",
                "\n",
                "install_if_missing(\"numpy\")\n",
                "install_if_missing(\"matplotlib\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2024-03-12 19:44:34.106222+0300 mojo-repl-entry-point[17076:8046464] [General] ERROR: Setting <View: 0x15441acf0> as the first responder for window <Window: 0x10c6763e0>, but it is in a different window ((null))! This would eventually crash when the view is freed. The first responder will be set to nil.\n",
                        "(\n",
                        "\t0   AppKit                              0x000000018f1b6870 -[NSWindow _validateFirstResponder:] + 332\n",
                        "\t1   AppKit                              0x000000018f1b66d8 -[NSWindow _setFirstResponder:] + 28\n",
                        "\t2   AppKit                              0x000000018f295c50 -[NSWindow _realMakeFirstResponder:] + 520\n",
                        "\t3   _macosx.cpython-312-darwin.so       0x000000010bd4756c FigureManager_init + 272\n",
                        "\t4   Python                              0x0000000105b0a6fc wrap_init + 20\n",
                        "\t5   Python                              0x0000000105a0bbdc wrapperdescr_call + 408\n",
                        "\t6   Python                              0x0000000105b66950 _PyObject_MakeTpCall + 128\n",
                        "\t7   Python                              0x00000001059f71c4 _PyEval_EvalFrameDefault + 44148\n",
                        "\t8   Python                              0x0000000105b66090 _PyObject_FastCallDictTstate + 96\n",
                        "\t9   Python                              0x0000000105b0a4f4 slot_tp_init + 212\n",
                        "\t10  Python                              0x0000000105afbbc4 type_call + 148\n",
                        "\t11  Python                              0x0000000105b66950 _PyObject_MakeTpCall + 128\n",
                        "\t12  Python                              0x00000001059f71c4 _PyEval_EvalFrameDefault + 44148\n",
                        "\t13  Python                              0x0000000105a739c0 method_vectorcall.llvm.6948146569891668407 + 308\n",
                        "\t14  Python                              0x00000001059d9934 _PyVectorcall_Call.llvm.7879633109753571798 + 152\n",
                        "\t15  Python                              0x00000001059f8c34 _PyEval_EvalFrameDefault + 50916\n",
                        "\t16  ???                                 0x00000001050f0d5c 0x0 + 4379839836\n",
                        "\t17  dyld                                0x000000018b5690e0 start + 2360\n",
                        ")\n"
                    ]
                }
            ],
            "source": [
                "def show_plot(tensor: Tensor[float_type]):\n",
                "    alias scale = 10\n",
                "    alias dpi = 64\n",
                "\n",
                "    np = Python.import_module(\"numpy\")\n",
                "    plt = Python.import_module(\"matplotlib.pyplot\")\n",
                "    colors = Python.import_module(\"matplotlib.colors\")\n",
                "\n",
                "    numpy_array = np.zeros((height, width), np.float64)\n",
                "\n",
                "    for row in range(height):\n",
                "        for col in range(width):\n",
                "            numpy_array.itemset((col, row), tensor[col, row])\n",
                "\n",
                "    fig = plt.figure(1, [scale, scale * height // width], dpi)\n",
                "    ax = fig.add_axes([0.0, 0.0, 1.0, 1.0], False, 1)\n",
                "    light = colors.LightSource(315, 10, 0, 1, 1, 0)\n",
                "\n",
                "    image = light.shade(numpy_array, plt.cm.hot, colors.PowerNorm(0.3), \"hsv\", 0, 0, 1.5)\n",
                "    plt.imshow(image)\n",
                "    plt.axis(\"off\")\n",
                "    plt.show()\n",
                "\n",
                "show_plot(compute_mandelbrot())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Vectorizing Mandelbrot\n",
                "We showed a naive implementation of the Mandelbrot algorithm, but there are two things we can do to speed it up. We can early-stop the loop iteration when a pixel is known to have escaped, and we can leverage Mojo's access to hardware by vectorizing the loop, computing multiple pixels simultaneously. To do that we will use the `vectorize` higher order generator.\n",
                "\n",
                "We start by defining our main iteration loop in a vectorized fashion"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "fn mandelbrot_kernel_SIMD[\n",
                "    simd_width: Int\n",
                "](c: ComplexSIMD[float_type, simd_width]) -> SIMD[float_type, simd_width]:\n",
                "    \"\"\"A vectorized implementation of the inner mandelbrot computation.\"\"\"\n",
                "    var cx = c.re\n",
                "    var cy = c.im\n",
                "    var x = SIMD[float_type, simd_width](0)\n",
                "    var y = SIMD[float_type, simd_width](0)\n",
                "    var y2 = SIMD[float_type, simd_width](0)\n",
                "    var iters = SIMD[float_type, simd_width](0)\n",
                "\n",
                "    var t: SIMD[DType.bool, simd_width] = True\n",
                "    for i in range(MAX_ITERS):\n",
                "        if not t.reduce_or():\n",
                "            break\n",
                "        y2 = y*y\n",
                "        y = x.fma(y + y, cy)\n",
                "        t = x.fma(x, y2) <= 4\n",
                "        x = x.fma(x, cx - y2)\n",
                "        iters = t.select(iters + 1, iters)\n",
                "    return iters"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The above function is parameterized on the `simd_width` and processes simd_width pixels. It only escapes once all pixels within the vector lane are done. We can use the same iteration loop as above, but this time we vectorize within each row instead. We use the `vectorize` generator to make this a simple function call."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Vectorized : 34.309600000000003 ms\n"
                    ]
                }
            ],
            "source": [
                "fn vectorized():\n",
                "    var t = Tensor[float_type](height, width)\n",
                "\n",
                "    @parameter\n",
                "    fn worker(row: Int):\n",
                "        var scale_x = (max_x - min_x) / width\n",
                "        var scale_y = (max_y - min_y) / height\n",
                "\n",
                "        @__copy_capture(scale_x, scale_y)\n",
                "        @parameter\n",
                "        fn compute_vector[simd_width: Int](col: Int):\n",
                "            \"\"\"Each time we oeprate on a `simd_width` vector of pixels.\"\"\"\n",
                "            var cx = min_x + (col + iota[float_type, simd_width]()) * scale_x\n",
                "            var cy = min_y + row * scale_y\n",
                "            var c = ComplexSIMD[float_type, simd_width](cx, cy)\n",
                "            t.data().simd_store[simd_width](\n",
                "                row * width + col, mandelbrot_kernel_SIMD[simd_width](c)\n",
                "            )\n",
                "\n",
                "        # Vectorize the call to compute_vector where call gets a chunk of pixels.\n",
                "        vectorize[compute_vector, simd_width](width)\n",
                "\n",
                "    @parameter\n",
                "    fn bench[simd_width: Int]():\n",
                "        for row in range(height):\n",
                "            worker(row)\n",
                "\n",
                "    var vectorized = benchmark.run[bench[simd_width]](\n",
                "        max_runtime_secs=0.5\n",
                "    ).mean(benchmark.Unit.ms)\n",
                "\n",
                "    print(\"Vectorized\", \":\", vectorized, \"ms\")\n",
                "\n",
                "    try:\n",
                "        _ = show_plot(t)\n",
                "    except e:\n",
                "        print(\"failed to show plot:\", e)\n",
                "\n",
                "vectorized()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Parallelizing Mandelbrot\n",
                "While the vectorized implementation above is efficient, we can get better performance by parallelizing on the cols. This again is simple in Mojo using the `parallelize` higher order function. Only the function that performs the invocation needs to change."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Parallelized: 4.0375750000000004 ms\n"
                    ]
                }
            ],
            "source": [
                "fn parallelized():\n",
                "    var t = Tensor[float_type](height, width)\n",
                "\n",
                "    @parameter\n",
                "    fn worker(row: Int):\n",
                "        var scale_x = (max_x - min_x) / width\n",
                "        var scale_y = (max_y - min_y) / height\n",
                "\n",
                "        @__copy_capture(scale_x, scale_y)\n",
                "        @parameter\n",
                "        fn compute_vector[simd_width: Int](col: Int):\n",
                "            \"\"\"Each time we oeprate on a `simd_width` vector of pixels.\"\"\"\n",
                "            var cx = min_x + (col + iota[float_type, simd_width]()) * scale_x\n",
                "            var cy = min_y + row * scale_y\n",
                "            var c = ComplexSIMD[float_type, simd_width](cx, cy)\n",
                "            t.data().simd_store[simd_width](row * width + col, mandelbrot_kernel_SIMD[simd_width](c))\n",
                "\n",
                "        # Vectorize the call to compute_vector where call gets a chunk of pixels.\n",
                "        vectorize[compute_vector, simd_width](width)\n",
                "\n",
                "\n",
                "    @parameter\n",
                "    fn bench_parallel[simd_width: Int]():\n",
                "        parallelize[worker](height, height)\n",
                "\n",
                "    var parallelized = benchmark.run[bench_parallel[simd_width]](\n",
                "        max_runtime_secs=0.5\n",
                "    ).mean(benchmark.Unit.ms)\n",
                "\n",
                "    print(\"Parallelized:\", parallelized, benchmark.Unit.ms)\n",
                "\n",
                "    try:\n",
                "        _ = show_plot(t)\n",
                "    except e:\n",
                "        print(\"failed to show plot:\", e)\n",
                "\n",
                "parallelized()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Benchmarking\n",
                "\n",
                "In this section we increase the size to 4096x4096 and run 1000 iterations for a larger test to stress the CPU "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "fn compare():\n",
                "    var t = Tensor[float_type](height, width)\n",
                "\n",
                "    @parameter\n",
                "    fn worker(row: Int):\n",
                "        var scale_x = (max_x - min_x) / width\n",
                "        var scale_y = (max_y - min_y) / height\n",
                "\n",
                "        @__copy_capture(scale_x, scale_y)\n",
                "        @parameter\n",
                "        fn compute_vector[simd_width: Int](col: Int):\n",
                "            \"\"\"Each time we oeprate on a `simd_width` vector of pixels.\"\"\"\n",
                "            var cx = min_x + (col + iota[float_type, simd_width]()) * scale_x\n",
                "            var cy = min_y + row * scale_y\n",
                "            var c = ComplexSIMD[float_type, simd_width](cx, cy)\n",
                "            t.data().simd_store[simd_width](\n",
                "                row * width + col, mandelbrot_kernel_SIMD[simd_width](c)\n",
                "            )\n",
                "\n",
                "        # Vectorize the call to compute_vector where call gets a chunk of pixels.\n",
                "        vectorize[compute_vector, simd_width](width)\n",
                "\n",
                "    @parameter\n",
                "    fn bench[simd_width: Int]():\n",
                "        for row in range(height):\n",
                "            worker(row)\n",
                "\n",
                "    var vectorized = benchmark.run[bench[simd_width]](\n",
                "        max_runtime_secs=0.5\n",
                "    ).mean(benchmark.Unit.ms)\n",
                "    print(\"Number of threads:\", num_physical_cores())\n",
                "    print(\"Vectorized:\", vectorized, \"ms\")\n",
                "\n",
                "    # Parallelized\n",
                "    @parameter\n",
                "    fn bench_parallel[simd_width: Int]():\n",
                "        parallelize[worker](height, height)\n",
                "\n",
                "    var parallelized = benchmark.run[bench_parallel[simd_width]](\n",
                "        max_runtime_secs=0.5\n",
                "    ).mean(benchmark.Unit.ms)\n",
                "    print(\"Parallelized:\", parallelized, \"ms\")\n",
                "    print(\"Parallel speedup:\", vectorized / parallelized)\n",
                "\n",
                "    _ = t # Make sure tensor isn't destroyed before benchmark is finished"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of threads: 10\n",
                        "Vectorized: 34.790599999999998 ms\n",
                        "Parallelized: 4.1929350000000003 ms\n",
                        "Parallel speedup: 8.2974336592386937\n"
                    ]
                }
            ],
            "source": [
                "#| CHECK: speedup\n",
                "compare()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Mojo",
            "language": "mojo",
            "name": "mojo-jupyter-kernel"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "mojo"
            },
            "file_extension": ".mojo",
            "mimetype": "text/x-mojo",
            "name": "mojo"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
